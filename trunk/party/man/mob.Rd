\name{mob}
\alias{mob}
\alias{coef.mob}
\alias{fitted.mob}
\alias{plot.mob}
\alias{predict.mob}
\alias{print.mob}
\alias{residuals.mob}
\alias{sctest.mob}
\alias{summary.mob}
\title{Model-based Recursive Partitioning}
\description{
  MOB is an algorithm for model-based recursive partitioning yielding
  a tree with fitted models in each terminal node.
}
\usage{
mob(formula, weights, data = list(), model = glinearModel,
  control = mob_control(), \dots)

\method{predict}{mob}(object, newdata = NULL, type = c("response", "node"), \dots)
\method{summary}{mob}(object, node = NULL, \dots)
\method{coef}{mob}(object, node = NULL, \dots)
\method{sctest}{mob}(object, node = NULL, \dots)
}
\arguments{
  \item{formula}{A symbolic description of the model to be fit. This
    should be of type \code{y ~ x1 + \dots + xk | z1 + \dots + zl} where
    the variables before the \code{|} are passed to the \code{model} and
    the variables after the \code{|} are used for partitioning.}
  \item{weights}{An optional vector of weights to be used in the fitting
    process. Only non-negative integer valued weights are allowed (default = 1).}
  \item{data}{An data frame containing the variables in the model.}
  \item{model}{A model of class \code{\link{StatModel-class}}. See details
    for requirements.}
  \item{control}{A list with control parameters as returned by
    \code{\link{mob_control}}.}
  \item{\dots}{Additional arguments passed to the \code{\link{fit}} call for
    the \code{model}.
  \item{object}{A fitted \code{mob} object.}
  \item{newdata}{A data frame with new inputs, by default the learning data
    is used.}
  \item{type}{A character string specifying whether the response should be
    predicted (inherited from the \code{predict} method for the \code{model})
    or the ID of the associated terminal node.}
  \item{node}{A vector of node IDs for which the corresponding method should
    be applied.}
}
\details{

Model-based partitioning fits a model tree using the following algorithm:
  {\enumerate
    \item \code{fit} a \code{model} with \formula{y ~ x1 + \dots + xk} for the
           observations in the current node.
    \item Assess the stability of the model parameters with respect to each
          of the partitioning variables \code{z1}, \dots, \code{zl}. If
	  there is some overall instability, choose the variable \code{z}
	  associated with the smallest p-value for partitioning, otherwise
	  stop. For performing the parameter instability fluctuation test,
	  a \code{\link{estfun}} method and a \code{\link{weights}} method is
	  needed.
    \item Search for the locally optimal split in \code{z} by minimizing the
          objective function of the \code{model}. Typically, this will be
	  something like \code{\link{deviance}} or the negative \code{\link{logLik}}
	  and can be specified in \code{\link{mob_control}}.
    \item Re-fit the \code{model} in both children, using \code{\link{reweight}}
          and repeat from step 2.
  }
For the fitted MOB tree, several standard methods are inherited if they are
available for fitted \code{model}s, such as \code{print}, \code{predict},
\code{residuals}, \code{residuals}, \code{coef} and \code{summary}. The latter
two return the coefficients and summary by default for all terminal nodes,
but take a \code{node} argument that can be set to any node ID. The \code{sctest}
method extracts the results of the parameter stability tests (aka structural 
change tests) for any given node, by default for all nodes.
}
\value{
  An object of class \code{mob} inheriting from \code{\link{BinaryTree-class}}.
}
\references{ 

   Torsten Hothorn, Kurt Hornik and Achim Zeileis (2006). Unbiased Recursive
   Partitioning: A Conditional Inference Framework. \emph{Journal of
   Computational and Graphical Statistics} (accepted). Preprint available
   from \url{http://statmath.wu-wien.ac.at/~zeileis/papers/Hothorn+Hornik+Zeileis-2006.pdf}

   Helmut Strasser and Christian Weber (1999). On the asymptotic theory of permutation
   statistics. \emph{Mathematical Methods of Statistics}, \bold{8}, 220--250.

}
\examples{

if(require("mlbench")) {

## recursive partitioning of a linear regression model
## load data
data("BostonHousing", package = "mlbench")
## and transform variables appropriately (for a linear regression)
BostonHousing$lstat <- log(BostonHousing$lstat)
BostonHousing$rm <- BostonHousing$rm^2

## partition the linear regression model medv ~ lstat + rm
## with respect to all remaining variables:
fm <- mob(medv ~ lstat + rm | zn + indus + chas + nox + age + dis + rad + tax + crim + b + ptratio,
  control = mob_control(minsplit = 40), data = BostonHousing, model = linearModel)

## print the resulting tree
fm
## or better visualize it
plot(fm, tnex = 4)

## extract coefficients in all terminal nodes
coef(fm)
## look at full summary, e.g., for node 9
summary(fm, node = 9)

## compute mean squared error (on training data)
mean((BostonHousing$medv - fitted(fm))^2)
mean(residuals(fm)^2)

}
}
\keyword{tree}
